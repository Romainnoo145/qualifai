---
phase: 28-source-discovery-with-provenance
plan: 02
type: execute
wave: 2
depends_on:
  - 28-01
files_modified:
  - lib/research-executor.ts
  - server/routers/research.ts
autonomous: true
requirements:
  - DISC-01
  - DISC-03

must_haves:
  truths:
    - "After running research, the research run's inputSnapshot contains a sourceSet with provenance-tagged DiscoveredUrl[] entries"
    - 'Re-running research within 24h does not trigger new SerpAPI calls — serpDiscoveredAt timestamp is respected'
    - 'Admin can trigger re-discovery independently of a full research run via rediscoverSources mutation'
    - 'Re-discovery only updates inputSnapshot.sourceSet — does not clear evidence, hypotheses, or change run status'
    - 'Existing inputSnapshot fields (manualUrls, campaignId, deepCrawl) are preserved when sourceSet is written'
  artifacts:
    - path: 'lib/research-executor.ts'
      provides: 'executeResearchRun now builds and persists sourceSet to inputSnapshot, derives researchUrls from sourceSet'
      contains: 'buildSourceSet'
    - path: 'server/routers/research.ts'
      provides: 'rediscoverSources tRPC mutation with 24h SERP cache guard and force bypass'
      exports: ['researchRouter']
  key_links:
    - from: 'lib/research-executor.ts'
      to: 'lib/enrichment/source-discovery.ts'
      via: 'import { buildSourceSet, defaultResearchUrls, extractSourceSet }'
      pattern: 'buildSourceSet'
    - from: 'server/routers/research.ts'
      to: 'lib/enrichment/source-discovery.ts'
      via: 'import { buildSourceSet, defaultResearchUrls, extractSourceSet }'
      pattern: 'rediscoverSources'
    - from: 'lib/research-executor.ts'
      to: 'prisma ResearchRun.inputSnapshot'
      via: 'toJson({ ...existing, sourceSet })'
      pattern: 'sourceSet'
---

<objective>
Integrate `buildSourceSet()` into the research executor and add a `rediscoverSources` tRPC mutation. After this plan, every research run persists a provenance-tagged source set to `inputSnapshot.sourceSet`, the SERP 24h cache is enforced centrally, and admin can trigger re-discovery independently.

Purpose: Wire the pure logic from Plan 01 into the live pipeline, ensuring provenance data flows from discovery through to persistence.

Output: Modified `research-executor.ts` and `research.ts` router.
</objective>

<execution_context>
@/home/klarifai/.claude/get-shit-done/workflows/execute-plan.md
@/home/klarifai/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/28-source-discovery-with-provenance/28-RESEARCH.md
@.planning/phases/28-source-discovery-with-provenance/28-01-SUMMARY.md

# Files being modified:

@lib/research-executor.ts
@server/routers/research.ts

# Dependencies:

@lib/enrichment/source-discovery.ts (from Plan 01)
@lib/enrichment/sitemap.ts
@lib/enrichment/serp.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Integrate buildSourceSet into research executor</name>
  <files>lib/research-executor.ts</files>
  <action>
Modify `lib/research-executor.ts` to build and persist a sourceSet during every research run:

**Imports:**

- Add: `import { buildSourceSet, defaultResearchUrls as defaultResearchUrlsFn, extractSourceSet, type SourceSet } from '@/lib/enrichment/source-discovery'`
- Remove the local `defaultResearchUrls` function (lines 51-77) — it now lives in source-discovery.ts
- Keep the local `uniqueUrls`, `toJson`, `manualUrlsFromSnapshot`, `extractSerpCache`, `extractSitemapCache` functions (they still serve the existing pipeline; serpCache/sitemapCache are read for backward compatibility but sourceSet is the canonical source going forward)

**In executeResearchRun, after sitemap + SERP discovery completes but BEFORE the URL list is consumed by evidence extraction:**

1. Pre-read existing sourceSet from prior snapshot (same "pre-read before overwrite" pattern used for sitemapCache at lines 154-167):

   ```typescript
   const priorSourceSet = extractSourceSet(priorSnapshot);
   ```

2. Check SERP cache using sourceSet.serpDiscoveredAt:

   ```typescript
   const serpAge = priorSourceSet?.serpDiscoveredAt
     ? Date.now() - new Date(priorSourceSet.serpDiscoveredAt).getTime()
     : Infinity;
   const useSerpFromSourceSet = serpAge < 24 * 60 * 60 * 1000;
   ```

3. Build the sourceSet:

   ```typescript
   const sourceSet = buildSourceSet({
     sitemapUrls: sitemapUrls, // already discovered above
     serpUrls: useSerpFromSourceSet
       ? []
       : [...serpResult.reviewUrls, ...serpResult.jobUrls],
     defaultUrls: defaultResearchUrlsFn(prospect.domain),
     serpDiscoveredAt: useSerpFromSourceSet
       ? priorSourceSet!.serpDiscoveredAt
       : new Date().toISOString(),
   });
   ```

4. Derive researchUrls from sourceSet instead of the current ad-hoc assembly:

   ```typescript
   const researchUrls = sourceSet.urls.map((u) => u.url);
   ```

   This replaces the existing `researchUrls = uniqueUrls(sitemapUrls.length > 0 ? [...] : [...])` block.

5. Persist sourceSet to inputSnapshot — spread existing snapshot fields to avoid loss (Pitfall 2 from research):
   ```typescript
   // In the researchRun update call:
   inputSnapshot: toJson({ ...existingSnapshot, sourceSet }),
   ```

**IMPORTANT — preserve backward compatibility:**

- Keep writing `sitemapCache` and `serpCache` alongside `sourceSet` for now (Phase 29 will deprecate them)
- The existing `manualUrls` handling must remain — manual URLs should be included in the `default` provenance bucket (they are user-provided, conceptually "default" sources)
- Non-review manual URLs (used in the current code for evidence extraction) should still work as before

**Handle the SERP cache guard consolidation:**

- The existing code in the deepCrawl branch already checks `serpCache` age. After this change, the sourceSet-level `serpDiscoveredAt` check at the top of the function should be the single SERP cache guard. The deepCrawl branch's serpCache check can remain as a secondary safety net but should not trigger redundant SERP calls.
  </action>
  <verify>
  <automated>cd /home/klarifai/Documents/klarifai/projects/qualifai && npm run check 2>&1 | tail -20</automated>
  <manual>Read lib/research-executor.ts and confirm: (1) buildSourceSet is called, (2) sourceSet is persisted to inputSnapshot, (3) researchUrls derived from sourceSet.urls, (4) defaultResearchUrls imported from source-discovery.ts not defined locally</manual>
  </verify>
  <done>Research executor builds sourceSet during every run, persists it to inputSnapshot.sourceSet, derives researchUrls from the sourceSet, and respects 24h SERP cache via serpDiscoveredAt. Local defaultResearchUrls removed (imported from source-discovery.ts).</done>
  </task>

<task type="auto">
  <name>Task 2: Add rediscoverSources tRPC mutation</name>
  <files>server/routers/research.ts</files>
  <action>
Add a `rediscoverSources` mutation to the research router in `server/routers/research.ts`:

**Input schema:**

```typescript
z.object({
  runId: z.string(),
  force: z.boolean().default(false), // bypass 24h SERP cache
});
```

**Implementation:**

1. Fetch the ResearchRun by ID (include prospectId, inputSnapshot)
2. Fetch the Prospect (domain, companyName)
3. Extract existing sourceSet from inputSnapshot using `extractSourceSet()`
4. SERP cache guard: check `sourceSet.serpDiscoveredAt` age. If < 24h AND force=false, skip SERP discovery. If force=true, always call SERP (admin explicitly bypasses cache).
5. Call `discoverSitemapUrls(prospect.domain)` — always refresh sitemap
6. Call `discoverSerpUrls(...)` only if SERP cache is stale or force=true
7. Build new sourceSet via `buildSourceSet({ sitemapUrls, serpUrls, defaultUrls: defaultResearchUrls(prospect.domain), serpDiscoveredAt })`
8. Merge into inputSnapshot: `toJson({ ...existing, sourceSet })` — spread all existing fields (Pitfall 2)
9. Update the ResearchRun with the new inputSnapshot
10. Return `{ sourceSet }`

**CRITICAL — rediscoverSources does NOT:**

- Delete evidence items
- Delete hypotheses or opportunities
- Change run status
- Trigger evidence extraction
- Clear any other inputSnapshot fields

It ONLY updates `inputSnapshot.sourceSet`.

**Use `adminProcedure`** (same as all other mutations in this router). Import `discoverSitemapUrls` from `@/lib/enrichment/sitemap`, `discoverSerpUrls` from `@/lib/enrichment/serp`, `buildSourceSet`, `defaultResearchUrls`, `extractSourceSet` from `@/lib/enrichment/source-discovery`.

**Import the existing `toJson` pattern** — either import from research-executor or define inline (it is a 3-line cast function). Since research-executor does not export toJson, define it inline in this mutation or in a shared location. Keep it simple: define inline.
</action>
<verify>
<automated>cd /home/klarifai/Documents/klarifai/projects/qualifai && npm run check 2>&1 | tail -20</automated>
<manual>Verify rediscoverSources mutation exists in research router, uses adminProcedure, accepts runId + force, returns sourceSet</manual>
</verify>
<done>rediscoverSources mutation exists on the research router, accepts runId + optional force boolean, respects 24h SERP cache (force bypasses), persists sourceSet to inputSnapshot without touching evidence/hypotheses/status, returns the new sourceSet.</done>
</task>

</tasks>

<verification>
- `npm run check` — no type errors across entire project
- `npx tsx -e "import { researchRouter } from './server/routers/research'"` — router loads
- Grep for `buildSourceSet` in research-executor.ts — must appear
- Grep for `rediscoverSources` in research.ts — must appear
- Grep for `sourceSet` in research-executor.ts inputSnapshot writes — must appear
</verification>

<success_criteria>

- research-executor.ts calls buildSourceSet() and persists sourceSet to inputSnapshot
- researchUrls are derived from sourceSet.urls (not ad-hoc assembly)
- rediscoverSources tRPC mutation exists with SERP cache guard + force bypass
- npm run check passes
- No existing functionality broken (manualUrls, sitemapCache, serpCache still work)
  </success_criteria>

<output>
After completion, create `.planning/phases/28-source-discovery-with-provenance/28-02-SUMMARY.md`
</output>
