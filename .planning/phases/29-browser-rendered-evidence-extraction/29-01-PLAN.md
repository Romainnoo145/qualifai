---
phase: 29-browser-rendered-evidence-extraction
plan: 01
type: tdd
wave: 1
depends_on: []
files_modified:
  - lib/web-evidence-adapter.ts
  - lib/web-evidence-adapter.test.ts
autonomous: true
requirements: [EXTR-01, EXTR-02, EXTR-03]

must_haves:
  truths:
    - 'URLs with jsHeavyHint=true or sourceType REVIEWS route directly to Crawl4AI without stealth attempt'
    - 'Static pages returning fewer than 500 chars from stealth escalate to Crawl4AI'
    - 'No more than 5 URLs per batch use browser-rendered extraction'
    - 'Budget-exhausted URLs receive a fallback draft instead of crashing'
    - 'Crawl4AI-escalated drafts get correct workflowTag from detectWorkflowTag, not default'
  artifacts:
    - path: 'lib/web-evidence-adapter.ts'
      provides: 'Two-tier extraction routing with budget cap'
      contains: 'BROWSER_BUDGET_MAX'
    - path: 'lib/web-evidence-adapter.test.ts'
      provides: 'Tests covering direct-route, escalation, and budget enforcement'
      min_lines: 60
  key_links:
    - from: 'lib/web-evidence-adapter.ts'
      to: 'lib/enrichment/crawl4ai.ts'
      via: 'extractMarkdown import'
      pattern: 'import.*extractMarkdown.*crawl4ai'
    - from: 'lib/web-evidence-adapter.ts'
      to: 'lib/enrichment/source-discovery.ts'
      via: 'detectJsHeavy import'
      pattern: 'import.*detectJsHeavy.*source-discovery'
---

<objective>
Implement two-tier extraction routing in `ingestWebsiteEvidenceDrafts` using TDD: browser-direct routing for JS-heavy / REVIEWS URLs, 500-char stealth escalation, and 5-URL browser budget cap.

Purpose: JS-heavy pages that previously returned empty or near-empty content now yield usable evidence through Crawl4AI browser extraction, with a budget cap to bound pipeline duration.

Output: Modified `ingestWebsiteEvidenceDrafts` with full test coverage, backwards-compatible signature.
</objective>

<execution_context>
@/home/klarifai/.claude/get-shit-done/workflows/execute-plan.md
@/home/klarifai/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/29-browser-rendered-evidence-extraction/29-RESEARCH.md

@lib/web-evidence-adapter.ts
@lib/web-evidence-adapter.test.ts
@lib/enrichment/crawl4ai.ts
@lib/enrichment/source-discovery.ts
@lib/enrichment/scrapling.ts
</context>

<feature>
  <name>Two-tier extraction routing with browser budget</name>
  <files>lib/web-evidence-adapter.ts, lib/web-evidence-adapter.test.ts</files>
  <behavior>
    The modified `ingestWebsiteEvidenceDrafts(urls, options?)` routes URLs through a two-tier extraction pipeline:

    **Tier routing (per URL):**
    1. If `sourceType === 'REVIEWS'` OR `jsHeavyHint === true` (from options.jsHeavyHints map, falling back to `detectJsHeavy(url)`):
       - Direct to Crawl4AI via `extractMarkdown(url)` — skip stealth entirely
       - Decrement browserBudget
    2. Otherwise: stealth-first via `fetchStealth(url)`
       - If stealth returns `ok=false` OR html.length < 500:
         - Escalate to Crawl4AI via `extractMarkdown(url)` (if browserBudget > 0)
         - Decrement browserBudget
       - If stealth returns sufficient HTML (>= 500 chars):
         - Process through existing `extractWebsiteEvidenceFromHtml` path (soft-404, tech clues, etc.)

    **Budget enforcement:**
    - `BROWSER_BUDGET_MAX = 5` (module-level constant)
    - `let browserBudget = BROWSER_BUDGET_MAX` initialized once before the URL loop
    - Every `extractMarkdown()` call decrements it
    - When budget is 0, remaining browser-needing URLs get a `budgetExhaustedDraft` (fallback)

    **Crawl4AI markdown -> EvidenceDraft conversion:**
    - Use `buildCrawl4aiDraft({ sourceUrl, sourceType, markdown, title })` helper
    - Call `detectWorkflowTag(sourceType, markdown)` for correct tag (not default 'workflow-context')
    - Call `baseConfidence(sourceType)` for confidence
    - Set metadata: `{ adapter: 'crawl4ai-escalation', source: 'browser-rendered' }`
    - If markdown.length < 80: push fallback draft instead (matches existing Crawl4AI 80-char minimum)
    - If `looksLikeCrawled404(markdown)`: skip (import from crawl4ai.ts or reuse soft-404 pattern inline)

    **Raw fetch removal:**
    - Remove the raw `fetch()` fallback tier inside `ingestWebsiteEvidenceDrafts`. The escalation chain is now: Scrapling -> Crawl4AI -> fallback draft. This avoids double-budget consumption (Research Pitfall 5).

    **Signature (backwards-compatible):**
    ```typescript
    export async function ingestWebsiteEvidenceDrafts(
      urls: string[],
      options?: { jsHeavyHints?: Map<string, boolean> },
    ): Promise<EvidenceDraft[]>
    ```

    **Test cases:**
    - `direct-route: REVIEWS url → extractMarkdown called, fetchStealth NOT called`
    - `direct-route: jsHeavyHint=true url → extractMarkdown called, fetchStealth NOT called`
    - `escalation: stealth returns <500 chars → extractMarkdown called`
    - `no-escalation: stealth returns >=500 chars → extractMarkdown NOT called, extractWebsiteEvidenceFromHtml used`
    - `budget-cap: 7 JS-heavy URLs → only first 5 call extractMarkdown, last 2 get budgetExhaustedDraft`
    - `budget-shared: 3 direct + 3 escalated → budget tracks across both paths`
    - `crawl4ai-draft: markdown gets detectWorkflowTag, not default tag`
    - `backwards-compat: calling without options works (no jsHeavyHints param)`
    - `404-detection: crawl4ai markdown with "page not found" → skipped`

  </behavior>
  <implementation>
    1. RED: Write test file with all cases above. Mock `fetchStealth` and `extractMarkdown` using vi.mock. Tests MUST fail initially (function does not accept options, does not call extractMarkdown, has no budget).

    2. GREEN: Modify `ingestWebsiteEvidenceDrafts` in web-evidence-adapter.ts:
       - Add imports: `extractMarkdown` from crawl4ai.ts, `detectJsHeavy` from source-discovery.ts
       - Add module-level `BROWSER_BUDGET_MAX = 5` constant (export for test access)
       - Add `shouldUseBrowserDirect(sourceType, jsHeavyHint)` — returns true for REVIEWS or jsHeavyHint=true
       - Add `buildCrawl4aiDraft({ sourceUrl, sourceType, markdown, title })` helper
       - Add `budgetExhaustedDraft(sourceUrl, sourceType)` helper (similar to fallbackDraft but with metadata indicating budget exhaustion)
       - Modify `ingestWebsiteEvidenceDrafts` signature to accept optional `options`
       - Replace the per-URL loop body with the two-tier routing logic
       - Remove the raw `fetch()` fallback tier entirely
       - Keep soft-404 check for stealth-HTML path
       - Add crawled-404 check for Crawl4AI markdown path (inline, same indicators as looksLikeSoft404)

    3. REFACTOR: Clean up any redundancy. Ensure all helper functions are well-named and the control flow in the main loop is readable.

  </implementation>
</feature>

<verification>
```bash
npx vitest run lib/web-evidence-adapter.test.ts --reporter=verbose
npm run check
```
</verification>

<success_criteria>

- All test cases pass covering direct-route, escalation, budget cap, and backwards compatibility
- `npm run check` passes (TypeScript + lint + format)
- `BROWSER_BUDGET_MAX = 5` is a module-level exported constant
- Raw `fetch()` fallback tier is removed from `ingestWebsiteEvidenceDrafts`
- Function signature is backwards-compatible (options param is optional)
  </success_criteria>

<output>
After completion, create `.planning/phases/29-browser-rendered-evidence-extraction/29-01-SUMMARY.md`
</output>
