---
phase: 26.1-evidence-pipeline-expansion
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - prisma/schema.prisma
  - prisma/migrations/20260228_add_linkedin_news_source_types/migration.sql
  - lib/workflow-engine.ts
  - lib/research-executor.ts
  - scripts/backfill-linkedin-source-type.ts
autonomous: true
requirements: [EXP-01, EXP-02]

must_haves:
  truths:
    - 'LINKEDIN and NEWS are valid EvidenceSourceType values in the Prisma schema and DB'
    - 'SERP runs on every deepCrawl pipeline invocation regardless of prior source failures'
    - 'inferSourceType returns LINKEDIN for linkedin.com URLs'
    - 'Existing EvidenceItems with WEBSITE sourceType and linkedin.com sourceUrl are re-classified to LINKEDIN after backfill'
  artifacts:
    - path: 'prisma/schema.prisma'
      provides: 'LINKEDIN and NEWS enum values in EvidenceSourceType'
      contains: 'LINKEDIN'
    - path: 'prisma/migrations/20260228_add_linkedin_news_source_types/migration.sql'
      provides: 'DB migration adding LINKEDIN and NEWS to the enum'
    - path: 'lib/workflow-engine.ts'
      provides: 'Updated inferSourceType, baseConfidence, CONTEXT_SOURCE_TYPES'
    - path: 'lib/research-executor.ts'
      provides: 'SERP runs outside deepCrawl gate (unconditional when deepCrawl=true)'
    - path: 'scripts/backfill-linkedin-source-type.ts'
      provides: 'One-shot script to re-classify WEBSITE LinkedIn evidence items'
  key_links:
    - from: 'prisma/schema.prisma'
      to: 'lib/workflow-engine.ts'
      via: 'EvidenceSourceType import from @prisma/client'
      pattern: 'LINKEDIN|NEWS'
    - from: 'lib/research-executor.ts'
      to: 'lib/enrichment/serp.ts'
      via: 'discoverSerpUrls called outside deepCrawl conditional'
      pattern: 'discoverSerpUrls'
---

<objective>
Lay the schema foundation for new source types and decouple the SERP gate from deepCrawl success, so downstream plans can add LINKEDIN and NEWS evidence without TypeScript errors.

Purpose: Phase 26 calibration needs 4-5 distinct source types per prospect. New source types LINKEDIN and NEWS must exist in the DB before any evidence records can be written with them. SERP currently only runs when deepCrawl=true — ungating it ensures third-party mention discovery is reliable.

Output: Updated schema + migration, updated workflow-engine inference, SERP running unconditionally when deepCrawl=true, backfill script for existing LinkedIn evidence.
</objective>

<execution_context>
@/home/klarifai/.claude/get-shit-done/workflows/execute-plan.md
@/home/klarifai/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/26.1-evidence-pipeline-expansion/26.1-CONTEXT.md

Key files:
@prisma/schema.prisma
@lib/workflow-engine.ts
@lib/research-executor.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add LINKEDIN and NEWS to schema + update workflow-engine inference</name>
  <files>
    prisma/schema.prisma
    prisma/migrations/20260228_add_linkedin_news_source_types/migration.sql
    lib/workflow-engine.ts
  </files>
  <action>
**prisma/schema.prisma** — Add two new values to `EvidenceSourceType` enum (after REGISTRY):
```
LINKEDIN  // Company posts and profile from LinkedIn public pages
NEWS      // Google News RSS mentions and press coverage
```

**Migration** — Because the project uses manual migrations (DB drift pattern from Phase 17), do NOT run `prisma migrate dev`. Instead:

1. Apply the enum change directly to the DB:

```bash
docker exec qualifai-db psql -U user -d qualifai -c "ALTER TYPE \"EvidenceSourceType\" ADD VALUE IF NOT EXISTS 'LINKEDIN'; ALTER TYPE \"EvidenceSourceType\" ADD VALUE IF NOT EXISTS 'NEWS';"
```

2. Create migration file at `prisma/migrations/20260228_add_linkedin_news_source_types/migration.sql` with content:

```sql
ALTER TYPE "EvidenceSourceType" ADD VALUE IF NOT EXISTS 'LINKEDIN';
ALTER TYPE "EvidenceSourceType" ADD VALUE IF NOT EXISTS 'NEWS';
```

3. Run `npx prisma generate` to regenerate client types.

**lib/workflow-engine.ts** — Three changes:

1. In `inferSourceType`: add LinkedIn detection before the `manual://` check:

```typescript
if (lowered.includes('linkedin.com')) return 'LINKEDIN';
```

2. In `baseConfidence` switch: add cases for the new types:

```typescript
case 'LINKEDIN': return 0.73;
case 'NEWS': return 0.70;
```

3. In `CONTEXT_SOURCE_TYPES` Set: add `'LINKEDIN'` and `'NEWS'` so they count toward context score in quality gate (external social proof is context, not pain-confirming):

```typescript
const CONTEXT_SOURCE_TYPES = new Set<EvidenceSourceType>([
  'WEBSITE',
  'DOCS',
  'HELP_CENTER',
  'REGISTRY',
  'LINKEDIN',
  'NEWS',
]);
```

Run `npm run check` after — fix all TypeScript errors before continuing.
</action>
<verify>
<automated>docker exec qualifai-db psql -U user -d qualifai -c "SELECT unnest(enum_range(NULL::\"EvidenceSourceType\"));" | grep -E "LINKEDIN|NEWS" && npx tsc --noEmit --project /home/klarifai/Documents/klarifai/projects/qualifai/tsconfig.json 2>&1 | grep -v "scripts/rerun-hypotheses" | head -20</automated>
<manual>Confirm DB enum contains LINKEDIN and NEWS; confirm no new TypeScript errors beyond pre-existing scripts/rerun-hypotheses.ts error</manual>
</verify>
<done>DB enum has LINKEDIN and NEWS values; Prisma client regenerated; inferSourceType returns LINKEDIN for linkedin.com URLs; no new TypeScript errors</done>
</task>

<task type="auto">
  <name>Task 2: Ungate SERP from deepCrawl success + LinkedIn backfill script</name>
  <files>
    lib/research-executor.ts
    scripts/backfill-linkedin-source-type.ts
  </files>
  <action>
**lib/research-executor.ts** — SERP gate removal (per CONTEXT.md locked decision):

Currently `discoverSerpUrls` is called INSIDE the `if (input.deepCrawl)` block and is gated behind that condition. The new behavior: SERP always runs when `deepCrawl=true`, independently of any prior source success/failure.

The current code structure (abbreviated):

```typescript
if (input.deepCrawl) {
  // SERP discovery
  const serpResult = isCacheValid ? serpCache : await discoverSerpUrls(...)
  // ... Crawl4AI using serpUrls
  // ... Google mentions
}
```

SERP already runs inside deepCrawl — the "gate removal" from CONTEXT.md means SERP is not conditioned on `websiteEvidenceDrafts.length > 0` or any other upstream success check. Verify the current code does NOT have any such additional condition. If found, remove it.

Also update the SERP query: change from the current `companyName ?? domain` query to use company name only (no city/industry qualifiers). Current `discoverSerpUrls` already does `const query = input.companyName ?? input.domain` — this is correct. No change needed there.

Add domain exclusion to `discoverGoogleSearchMentions` in `lib/enrichment/serp.ts`: after collecting mentions, filter out results where `url` contains `prospect.domain`. Currently the function only filters by snippet length. Add:

```typescript
// Filter out own-domain results (already covered by WEBSITE source type)
.filter(mention => !mention.url.includes(input.domain))
```

Apply this filter to the mentions array before the final `.slice(0, 12)`.

Pass `domain` to `discoverGoogleSearchMentions` call in `research-executor.ts` (it already takes `domain` in its input type — verify it's being passed correctly).

**scripts/backfill-linkedin-source-type.ts** — One-shot backfill script:

```typescript
// Usage: node -e "require('dotenv').config(); require('./scripts/backfill-linkedin-source-type.ts')"
// Or: npx ts-node scripts/backfill-linkedin-source-type.ts

import { PrismaPg } from '@prisma/adapter-pg';
import { Pool } from 'pg';
import { PrismaClient } from '@prisma/client';

async function main() {
  const pool = new Pool({ connectionString: process.env.DATABASE_URL });
  const adapter = new PrismaPg(pool);
  const db = new PrismaClient({ adapter });

  const result = await db.evidenceItem.updateMany({
    where: {
      sourceType: 'WEBSITE',
      sourceUrl: { contains: 'linkedin.com' },
    },
    data: { sourceType: 'LINKEDIN' },
  });

  console.log(
    `Backfilled ${result.count} LinkedIn evidence items from WEBSITE → LINKEDIN`,
  );
  await db.$disconnect();
  await pool.end();
}

main().catch(console.error);
```

Follow the project pattern: use `PrismaPg` adapter with `Pool` from pg (see MEMORY.md: "Prisma needs PrismaPg adapter with connectionString"). Also follow the `process.env` direct-read pattern (not env.mjs) and add `require('dotenv').config()` note per MEMORY.md CLI pattern.

Run `npm run check` — fix all errors.
</action>
<verify>
<automated>cd /home/klarifai/Documents/klarifai/projects/qualifai && npm run check 2>&1 | tail -10</automated>
<manual>Review research-executor.ts to confirm SERP has no upstream success gate; confirm backfill script exists and uses PrismaPg adapter</manual>
</verify>
<done>npm run check passes; SERP in research-executor.ts has no upstream success condition; backfill script at scripts/backfill-linkedin-source-type.ts uses PrismaPg adapter pattern; domain filter added to discoverGoogleSearchMentions</done>
</task>

</tasks>

<verification>
1. `docker exec qualifai-db psql -U user -d qualifai -c "SELECT unnest(enum_range(NULL::\"EvidenceSourceType\"));"` — shows LINKEDIN and NEWS
2. `npx tsc --noEmit` — only pre-existing error in scripts/rerun-hypotheses.ts
3. `npm run check` passes
4. `grep -n "LINKEDIN" lib/workflow-engine.ts` — returns inferSourceType and baseConfidence entries
5. `cat scripts/backfill-linkedin-source-type.ts` — contains PrismaPg, updateMany, linkedin.com filter
</verification>

<success_criteria>

- EvidenceSourceType enum has LINKEDIN and NEWS in DB and Prisma client
- inferSourceType('https://www.linkedin.com/company/foo') returns 'LINKEDIN'
- SERP in research-executor.ts runs unconditionally when deepCrawl=true (no upstream success gate)
- discoverGoogleSearchMentions filters out own-domain results
- backfill script exists and uses correct Prisma adapter pattern
- npm run check passes with no new errors
  </success_criteria>

<output>
After completion, create `.planning/phases/26.1-evidence-pipeline-expansion/26.1-01-SUMMARY.md`
</output>
