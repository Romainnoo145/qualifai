---
phase: 26.1-evidence-pipeline-expansion
plan: 02
type: execute
wave: 2
depends_on: [26.1-01]
files_modified:
  - lib/enrichment/google-reviews.ts
  - lib/enrichment/google-news.ts
  - lib/research-executor.ts
autonomous: true
requirements: [EXP-03, EXP-04]

must_haves:
  truths:
    - 'Google Reviews evidence items with REVIEWS sourceType appear after running pipeline on a prospect with a Google Maps listing'
    - 'Google News evidence items with NEWS sourceType appear after running pipeline on a prospect with news coverage'
    - "When either source returns zero results, a REVIEWS or NEWS evidence item is still recorded marking the attempt as 'not found'"
    - 'Neither source failure blocks the pipeline from completing'
  artifacts:
    - path: 'lib/enrichment/google-reviews.ts'
      provides: 'fetchGoogleReviews — Scrapling StealthyFetcher scrape of Google Maps reviews, returns EvidenceDraft[]'
      min_lines: 50
    - path: 'lib/enrichment/google-news.ts'
      provides: 'fetchGoogleNewsRss — RSS fetch for Google News, returns EvidenceDraft[]'
      min_lines: 40
    - path: 'lib/research-executor.ts'
      provides: 'google-reviews and google-news wired into pipeline with empty-result recording'
  key_links:
    - from: 'lib/enrichment/google-reviews.ts'
      to: 'lib/enrichment/scrapling.ts'
      via: 'fetchStealth import'
      pattern: 'fetchStealth'
    - from: 'lib/research-executor.ts'
      to: 'lib/enrichment/google-reviews.ts'
      via: 'fetchGoogleReviews import + call'
      pattern: 'fetchGoogleReviews'
    - from: 'lib/research-executor.ts'
      to: 'lib/enrichment/google-news.ts'
      via: 'fetchGoogleNewsRss import + call'
      pattern: 'fetchGoogleNewsRss'
---

<objective>
Add Google Reviews (via Scrapling) and Google News RSS as new evidence sources with proper empty-result recording so the pipeline produces REVIEWS and NEWS source types for real prospects.

Purpose: Phase 26 calibration needs 4-5 distinct source types. REVIEWS and NEWS are the two sources most likely to distinguish enterprise-scale prospects with external coverage from thin-web-presence SMBs.

Output: Two new enrichment modules + integration into research-executor.ts with diagnostic recording.
</objective>

<execution_context>
@/home/klarifai/.claude/get-shit-done/workflows/execute-plan.md
@/home/klarifai/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/STATE.md
@.planning/phases/26.1-evidence-pipeline-expansion/26.1-CONTEXT.md

Key files:
@lib/enrichment/scrapling.ts
@lib/enrichment/serp.ts
@lib/research-executor.ts
@lib/enrichment/kvk.ts
@.planning/phases/26.1-evidence-pipeline-expansion/26.1-01-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Google Reviews module via Scrapling</name>
  <files>lib/enrichment/google-reviews.ts</files>
  <action>
Create `lib/enrichment/google-reviews.ts`. This module takes the `mapsDataId` from SERP discovery and fetches the Google Maps reviews page via Scrapling StealthyFetcher to extract review text snippets.

**Strategy for getting the reviews page URL:**
Google Maps place pages follow the pattern: `https://www.google.com/maps/place/?q=place_id:{dataId}` — but the structured review data is not in the HTML. Instead, scrape the Google Search results page for reviews using the maps data_id URL or use the Google Maps reviews URL with `data_id`.

Since we have `mapsDataId` from SERP (stored in `serpCache.mapsDataId`), use the Google search reviews URL pattern:
`https://www.google.com/search?q={companyName}+reviews&num=10`

Scrape this page via `fetchStealth`. Parse review snippets from the HTML — Google embeds review text in `<span>` or `<div>` tags with data attributes. Use regex/string parsing (no external HTML parser — none in package.json).

**Interface and export:**

```typescript
import { fetchStealth } from '@/lib/enrichment/scrapling';
import type { EvidenceDraft } from '@/lib/workflow-engine';

export async function fetchGoogleReviews(input: {
  companyName: string;
  domain: string;
  mapsDataId?: string;
}): Promise<EvidenceDraft[]>;
```

**Implementation:**

1. Build URL: use `https://www.google.com/search?q=${encodeURIComponent(input.companyName)}+reviews+ervaringen&hl=nl&gl=nl`
2. `fetchStealth` the URL (30s timeout already in scrapling.ts client)
3. If `!result.ok` or `result.html.length < 500`: return empty array (caller handles empty-result recording)
4. Parse review snippets using regex: look for content between `"` markers in Google review snippets, or text within `<span data-ved` elements. Target: 3-5 review snippets, each 80-400 chars.
5. Filter snippets: `snippet.length >= 40 && snippet.length <= 400`, exclude navigation/UI text (Dutch: "meer", "lees", "bekijk")
6. Map each snippet to `EvidenceDraft`:

```typescript
{
  sourceType: 'REVIEWS',
  sourceUrl: `https://www.google.com/search?q=${encodeURIComponent(input.companyName)}+reviews`,
  title: `${input.companyName} - Google Reviews`,
  snippet: snippet.slice(0, 400),
  workflowTag: 'workflow-context',
  confidenceScore: 0.75,
  metadata: { adapter: 'google-reviews-scrapling', source: 'google-maps' },
}
```

7. Return up to 5 drafts — or [] if none found.
8. Wrap entire function in try/catch — any error returns [].

**Note on HTML parsing without cheerio:** Use regex and string indexOf to find review text. Google's search results page embeds reviews in sections preceded by patterns like `"sxaTd"` or star rating spans. If regex yields nothing, return []. Sparse results are acceptable — empty return is valid.
</action>
<verify>
<automated>cd /home/klarifai/Documents/klarifai/projects/qualifai && npx tsc --noEmit 2>&1 | grep "google-reviews" | head -5</automated>
<manual>Check that lib/enrichment/google-reviews.ts exports fetchGoogleReviews; confirm it uses fetchStealth not direct fetch; confirm try/catch wraps everything</manual>
</verify>
<done>lib/enrichment/google-reviews.ts exists, exports fetchGoogleReviews(input): Promise&lt;EvidenceDraft[]&gt;, uses fetchStealth, no TypeScript errors</done>
</task>

<task type="auto">
  <name>Task 2: Google News RSS module</name>
  <files>lib/enrichment/google-news.ts</files>
  <action>
Create `lib/enrichment/google-news.ts`. Fetches recent news mentions via the Google News RSS feed — public endpoint, no auth, no scraping complexity.

**Google News RSS URL pattern:**
`https://news.google.com/rss/search?q={query}&hl=nl&gl=NL&ceid=NL:nl`

**Interface:**

```typescript
import type { EvidenceDraft } from '@/lib/workflow-engine';

export async function fetchGoogleNewsRss(input: {
  companyName: string;
  domain: string;
}): Promise<EvidenceDraft[]>;
```

**Implementation:**

1. Build query: use company name only (no qualifiers) — `encodeURIComponent(input.companyName)`
2. Fetch RSS: standard `fetch()` with 10s timeout via `AbortSignal.timeout(10000)` — NO Scrapling needed (RSS is plain XML, no bot detection)
3. If `!response.ok` or response body empty: return []
4. Parse XML string with regex: extract `<item>` blocks, then extract `<title>`, `<description>`, `<link>`, `<pubDate>` from each item
5. Filter items: exclude items where link contains `input.domain` (own-domain coverage is already in WEBSITE source type)
6. Filter items: `pubDate` within last 12 months (convert `new Date(pubDate) > Date.now() - 365 * 24 * 60 * 60 * 1000`)
7. Map to `EvidenceDraft`:

```typescript
{
  sourceType: 'NEWS',
  sourceUrl: link,
  title: title.slice(0, 120),
  snippet: description.replace(/<[^>]+>/g, ' ').trim().slice(0, 400),
  workflowTag: 'workflow-context',
  confidenceScore: 0.70,
  metadata: { adapter: 'google-news-rss', pubDate },
}
```

8. Return up to 5 drafts (slice at end)
9. Wrap entire function in try/catch — any error returns []
10. No new package dependencies — use native fetch and regex XML parsing (RSS is simple enough)
    </action>
    <verify>
    <automated>cd /home/klarifai/Documents/klarifai/projects/qualifai && npx tsc --noEmit 2>&1 | grep "google-news" | head -5</automated>
    <manual>Check lib/enrichment/google-news.ts exports fetchGoogleNewsRss; confirm it uses native fetch (not Scrapling); confirm domain exclusion filter; confirm try/catch</manual>
    </verify>
    <done>lib/enrichment/google-news.ts exists, exports fetchGoogleNewsRss(input): Promise&lt;EvidenceDraft[]&gt;, uses native fetch with timeout, no TypeScript errors</done>
    </task>

<task type="auto">
  <name>Task 3: Wire Google Reviews + Google News into research-executor with empty-result recording</name>
  <files>lib/research-executor.ts</files>
  <action>
Integrate both new sources into `executeResearchRun` in `lib/research-executor.ts`.

**1. Add imports at top of file:**

```typescript
import { fetchGoogleReviews } from '@/lib/enrichment/google-reviews';
import { fetchGoogleNewsRss } from '@/lib/enrichment/google-news';
```

**2. Add new diagnostic source names** to the `SourceDiagnostic` union type:

```typescript
source: 'sitemap' |
  'website' |
  'reviews' |
  'serp' |
  'crawl4ai' |
  'google_mentions' |
  'kvk' |
  'linkedin' |
  'google_reviews' |
  'google_news';
```

**3. Wire Google Reviews inside `if (input.deepCrawl)` block**, after the Google mentions block. Use `serpResult.mapsDataId` (which may be undefined — handle gracefully):

```typescript
// Google Reviews via Scrapling (EVID-REVIEWS)
try {
  const reviewDrafts = await fetchGoogleReviews({
    companyName: prospect.companyName ?? prospect.domain,
    domain: prospect.domain,
    mapsDataId: serpResult.mapsDataId,
  });
  allDrafts.push(...reviewDrafts);
  // Empty result recording — always record the attempt
  if (reviewDrafts.length === 0) {
    allDrafts.push({
      sourceType: 'REVIEWS',
      sourceUrl: `https://www.google.com/search?q=${encodeURIComponent(prospect.companyName ?? prospect.domain)}+reviews`,
      title: `${prospect.companyName ?? prospect.domain} - Google Reviews (geen resultaten)`,
      snippet:
        'Google Reviews scrape did not find review snippets for this company.',
      workflowTag: 'workflow-context',
      confidenceScore: 0.1,
      metadata: { adapter: 'google-reviews-scrapling', notFound: true },
    });
  }
  diagnostics.push({
    source: 'google_reviews',
    status: reviewDrafts.length > 0 ? 'ok' : 'warning',
    message:
      reviewDrafts.length > 0
        ? `Google Reviews found ${reviewDrafts.length} review snippets.`
        : 'Google Reviews returned no results; placeholder recorded.',
  });
} catch (err) {
  console.error('[Google Reviews] scrape failed:', err);
  diagnostics.push({
    source: 'google_reviews',
    status: 'error',
    message: `Google Reviews scrape failed: ${err instanceof Error ? err.message : 'Unknown error'}`,
  });
}
```

**4. Wire Google News RSS inside `if (input.deepCrawl)` block**, after Google Reviews:

```typescript
// Google News RSS (EVID-NEWS)
try {
  const newsDrafts = await fetchGoogleNewsRss({
    companyName: prospect.companyName ?? prospect.domain,
    domain: prospect.domain,
  });
  allDrafts.push(...newsDrafts);
  // Empty result recording — always record the attempt
  if (newsDrafts.length === 0) {
    allDrafts.push({
      sourceType: 'NEWS',
      sourceUrl: `https://news.google.com/rss/search?q=${encodeURIComponent(prospect.companyName ?? prospect.domain)}`,
      title: `${prospect.companyName ?? prospect.domain} - Google News (geen resultaten)`,
      snippet:
        'Google News RSS returned no recent news coverage for this company.',
      workflowTag: 'workflow-context',
      confidenceScore: 0.1,
      metadata: { adapter: 'google-news-rss', notFound: true },
    });
  }
  diagnostics.push({
    source: 'google_news',
    status: newsDrafts.length > 0 ? 'ok' : 'warning',
    message:
      newsDrafts.length > 0
        ? `Google News RSS found ${newsDrafts.length} news items.`
        : 'Google News RSS returned no results; placeholder recorded.',
  });
} catch (err) {
  console.error('[Google News] RSS failed:', err);
  diagnostics.push({
    source: 'google_news',
    status: 'error',
    message: `Google News RSS failed: ${err instanceof Error ? err.message : 'Unknown error'}`,
  });
}
```

**5. Add skipped diagnostics** in the `else` branch (when deepCrawl is false):

```typescript
diagnostics.push({
  source: 'google_reviews',
  status: 'skipped',
  message: 'Google Reviews skipped (deep crawl disabled).',
});
diagnostics.push({
  source: 'google_news',
  status: 'skipped',
  message: 'Google News skipped (deep crawl disabled).',
});
```

**6. Raise evidence cap** from 36 to 48 to accommodate 2 new sources (up to 5 reviews + 5 news + 5-10 LinkedIn posts = 15+ additional items beyond existing cap). Update:

```typescript
const evidenceDrafts = dedupeEvidenceDrafts(allDrafts).slice(0, 48);
```

Run `npm run check` and fix all errors.
</action>
<verify>
<automated>cd /home/klarifai/Documents/klarifai/projects/qualifai && npm run check 2>&1 | tail -15</automated>
<manual>Grep research-executor.ts for fetchGoogleReviews and fetchGoogleNewsRss imports; verify empty-result recording blocks exist for both; verify evidence cap is 48</manual>
</verify>
<done>npm run check passes; research-executor.ts imports and calls both new modules; both sources have empty-result recording; evidence cap is 48; skipped diagnostics in else branch</done>
</task>

</tasks>

<verification>
1. `npm run check` — no errors
2. `grep -n "fetchGoogleReviews\|fetchGoogleNewsRss" lib/research-executor.ts` — both imported and called
3. `grep -n "notFound: true" lib/research-executor.ts` — empty-result recording lines found
4. `grep -n "slice(0, 48)" lib/research-executor.ts` — evidence cap raised
5. `ls lib/enrichment/google-reviews.ts lib/enrichment/google-news.ts` — both files exist
</verification>

<success_criteria>

- lib/enrichment/google-reviews.ts and google-news.ts exist and compile cleanly
- Both modules are wired into research-executor.ts within deepCrawl block
- Empty results always produce a placeholder evidence item (confidenceScore 0.10, notFound: true metadata)
- Neither source failure blocks the pipeline (try/catch everywhere)
- Evidence cap raised to 48
- npm run check passes
  </success_criteria>

<output>
After completion, create `.planning/phases/26.1-evidence-pipeline-expansion/26.1-02-SUMMARY.md`
</output>
