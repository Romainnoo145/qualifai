# Phase 26.1: Evidence Pipeline Expansion - Context

**Gathered:** 2026-02-28
**Status:** Ready for planning

<domain>
## Phase Boundary

Add new evidence sources and fix data quality gaps so Phase 26 threshold calibration has real multi-source data to work with. The pipeline currently only consistently produces WEBSITE + CAREERS source types. This phase expands to 4-5 distinct source types per prospect.

Target audience is generic Dutch B2B prospects — not just SMBs. Another customer tenant focuses on larger enterprises where news coverage and LinkedIn activity are meaningful signals.

New capabilities (analytics, scheduling, UI changes) belong in other phases.

</domain>

<decisions>
## Implementation Decisions

### Source scope

- Implement all 5 planned sources: SERP gate removal, Google Reviews via Scrapling, Google News RSS, LinkedIn posts, skip Trustpilot
- Trustpilot skipped — most prospects are B2B where Trustpilot presence is unlikely
- Google News RSS included because larger enterprise prospects do have news coverage
- All sources should be additive — no source failure should block the pipeline

### SERP gate removal

- SERP runs independently of deepCrawl success — the gate is removed entirely
- Query: company name only (no city/industry qualifiers — avoids zero results for uncommon names)
- Filter: exclude results pointing to the prospect's own domain (already covered by WEBSITE source type)
- SERP's value is third-party mentions: directories, partner listings, press, awards
- Depth: Claude decides based on pipeline performance (5-10 results is reasonable)

### Review source strategy

- Switch Google Reviews ingestion from current approach to Scrapling fetchStealth()
- Google Maps place ID sourced from SERP results (Google My Business listings appear in search)
- Coverage expectation: mixed for B2B — try anyway, sparse results are acceptable
- Empty result handling: always record an evidence item marking the attempt as "not found" (distinguishes "no data" from "not tried")

### LinkedIn posts

- Full Scrapling scrape of public company page posts — no login/credentials
- Target: last 5-10 publicly visible posts per company
- Data of interest: recent posts (company positioning, what they promote, pain signals)
- Failure handling: warn + continue — LinkedIn blocking should NOT halt the pipeline
- Backfill: existing prospects should be backfilled (re-classify existing records where LinkedIn URL was stored as WEBSITE source type)

### Google News RSS

- Collect recent news mentions via RSS (no auth, no scraping complexity)
- Useful signal for enterprise-size prospects; sparse for SMBs is acceptable

### Claude's Discretion

- SERP result depth (5 vs 10 results — balance coverage vs processing time)
- Exact Scrapling configuration for LinkedIn (headers, delays, retry logic)
- How to detect Google Maps place ID from SERP results (URL pattern or structured data)
- Compression/deduplication of evidence items across sources

</decisions>

<specifics>
## Specific Ideas

- LinkedIn company posts are the primary LinkedIn signal — what companies post reveals their current positioning, pain points, and priorities
- The pipeline must work for both SMB (sparse external data) and enterprise (rich sources) without failing on sparse results
- Phase 26 calibration needs real multi-source data — this phase is a prerequisite

</specifics>

<deferred>
## Deferred Ideas

- LinkedIn with credentials/auth — complex, risk of account ban, future phase if needed
- Trustpilot scraping — low B2B coverage, may revisit if customer profile changes
- LinkedIn Jobs section scraping — strong hiring signal, but separate from posts; future phase

</deferred>

---

_Phase: 26.1-evidence-pipeline-expansion_
_Context gathered: 2026-02-28_
